# 数据分析-06

## pandas的拼接操作

pandas和mysql非常相似

mysql可以对数据进行统计

pandas主要作用就是对数据进行一个统计pandas也有类似于left join 的操作select union select

```python
import numpy as np
import pandas as pd
```



pandas 的拼接有两种方法：

+ 级联：pd.concat, pd.append
+ 合并：pd.merge, pd.join

回顾numpy的级联

```python
a = np.random.randint(0,100,(5,4))
b = np.random.randint(0,100,(5,4))
np.concatenate((a,b),axis=1)
```

![image-20191111200617996](images/image-20191111200617996.png)

```python
A = pd.DataFrame(a)
B = pd.DataFrame(b)
pd.concat((A,B),axis=1)
```

![image-20191111200744327](images/image-20191111200744327.png)

### 使用pd.concat()级联

pandas使用pd.concat函数，与np.concatenate函数类似 只是多了一些参数：

pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None,levels=None, names=None, verify_integrity=False, copy=True)



```python
# 自动创建dataframe对象
def make_df(index, columns):
    data = {col:[str(col)+str(ind) for ind in indexs] for col in columns}
    return pd.DataFrame(data=data, index=indexs, columns=columns)

df1 = make_df(list(range(3), list=('abc'))
df1
              
df2 = make_df(list(range(2,5)), list('abc'))
df2
```

<img src="images/image-20191111201912259.png" alt="image-20191111201912259"  />![image-20191111201944440](images/image-20191111201944440.png)

### 简单级联

和np.concatenate一样 优先增加行数(默认axis=0)

```python
# 如果没有关型的索引，默认会把枚举型当做关联型使用
# select * from df1 inner df2 on df1.row=df2.row;
pd.concat([df1,df2], axis=1, join='inner')
```

![image-20191111202712729](images/image-20191111202712729.png)

```python
# select * from df1 union select * from df2;
# union联合查询的两个表 字段名可以不一致 数据类型可以不一致 字段的数量必须一致
pd.concat([df1,df2],axis=0,join='inner')
```

![image-20191111202924340](images/image-20191111202924340.png)

可以通过axis的值来改变级联方向

注意：index,columns在级联时可以重复



可以通过忽略ignore_idnex        重新索引

````python
pd.concat([df1,df2], axis=0, join='inner', ingore_inex=True)
````

![image-20191111203313326](images/image-20191111203313326.png)

或者使用多级索引keys

concat([x,y], keys=['x','y'])

```python
pd.concat([df1,df2], axis=0,join='inner', keys=['df1','df2'])
```

![image-20191111203622116](images/image-20191111203622116.png)

### 连接mysql数据库

```python
import pymysql
import pandas as pd
# 创建连接对象
conn = pymysql.connect(host='localhost',port=3306,user='root',passwd='abc123',db='data01')

# 游标
cursor = conn.cursor(cursor=pymysql.cursor.DictCursor)

# 查询
cursor.execute("select * from user_info limit 10")

userinfo = cursor.fetchall()

cursor.close()
conn.close()
pd.DataFrame(userinfo)
```

```python
from sqlalchemy import create_engine

# 注意 连接是可以指定字符集 通过?utf8 | ?utf-8 | charset=utf-8,如果不指定默认为utf8
conn = create_engine("mysql+pymysql://root:abc123@localhost:3306/data01?utf8")
sql = "select * from userinfo limit 10"
userinfo=pd.read_sql_query(sql,conn)


sql = "select * from orderinfo where user_id<11"
orderinfo=pd.read_sql_query(sql,conn)
```

### 不匹配级联

不匹配级联指的是级联的维度的索引不一致 例如纵向级联是列索引不一致 横向级联时行索引不一致

有3中连接方式

+ 外连接：不NaN(默认模式)

```python
pd.concat([userinfo, orderinfo], axis=1, join='outer')
```

+ 内连接：只连接匹配的项

+ 连接指定轴join_axes

```python
pd.concat([userinfo,order], axis=0, join_axes=[userinfo, columns])
```

### 使用append()函数添加

由于后面的级联的使用非常普遍 因此有一个函数append专门用于在后面添加

```python
new = orderinfo.loc[:,['orderid', 'price', 'ispaid']]


new.columns  = userinfo.columns

userinfo.append(new)

pd.concat([userinfo,new])]
```

### 使用pd.merge()合并

merge与concat的区别在于 merge需要依据某一个共同的行或者列来进行合并

使用pd.merge()合并时，会自动根据两者相同columns名称的那一列，作为key来进行合并

注意：每一列元素的顺序不要求一致

如果两个表的关联字段的名称不一致 需要通过 left_on 和 right_on 指定关联字段

+ 一对一合并

```python
#left, right, how='inner'
#select * from userinfo join orderinfo using(userid) where userid<11;
#用户的真实信息和用户的虚拟信息     男  姓名  idcard  
pd.merge(userinfo,orderinfo)
```

+ 多对一|一对多合并
+ 多对多合并

```python
df1 = make_df(range(5), columns=['id', 'name', 'sex'])
df1.id = [1,1,3,4,3]
df1
```

```python
pd.merge(df1,df2)  # 把多对多改变为一对多的方式
```

+ key的规范化

通过修改字段的名称的完成连接操作

```python
userinfo.columns = ['id', 'name', 'birth']
userinfo

# 使用on来指定关联
pd.merge(userinfo, orderinfo, left_on='id', right_on='userid')
```

将某一列设置为行号

set_index()

```python
userinfo.set_index(keys='id', inplace=True)

orderinfo.set_index(keys='userid', inplace=True)

# left_index=True 指定左边的行索引为关联列
pd.merge(userinfo, orderinfo,left_index=True, right_index=True)
```

+ 使用on=显式指定哪一列为key，当有多个key相同时使用
+ 使用left_on 和 right_on 指定左右两边的列作为key 当左右两边的key都不相等时使用

#### 内合并和外合并

+ 内合并：只保留两者都有的key(默认模式)
+ 外合并 how='outer'：补NaN
+ 左合并和右合并：how='left', how='right'

```python
# 删除
orderinfo.drop(labels=9, axis=0, inplace=True)
userinfo.drop(labels=4, inplace=True)

pd.merge(userinfo, orderinfo, left_index=True, right_index=True, how='outer')
```

#### 数据合并练习

```python
import numpy as np
import pandas as pd
import warnings

warning.filterwarnings('ignore')
```

```python
# 导入文件
abb = pd.read_csv('./state-abbrevs.csv')
are = pd.read_csv('./state-areas.csv')
pop = pd.read_csv('./state-population.csv')
```

```python
abb.head()
```

![image-20191111220436059](images/image-20191111220436059.png)

```python
are.head()
```

![image-20191111220522143](images/image-20191111220522143.png)

```python
pop.head()
```

![image-20191111220604312](images/image-20191111220604312.png)

```python
pop_col = pop.colums.tolist()
pop_col[0] = 'state_region'
pop.columns = pop_col

pop.shape
```

```python
abb.shape
pop_abb = pd.merge(popm abb, left_on='state_region', right_on='abbreviation', how='outer')

pop_abb.head()
pop_abb.isnull().sum()

# 删除指定列
pop_abb.drop('abbreviation', axis=1, inplace=True)
```

```python
cond = pop_abb.state.isnull()
# 找到指定列 并找到对应的列索引 进行去重
pop_abb['state_region'][cond].unique()
```

```python
# 将state_region为PR对应的state列为nan的值转换为Puerto Rico
cond_pr = pop_abb.state_region == 'PR'
pop_abb['state'][cond_pr] = 'Puerto Rico'
```

```python
# 将state_region为USA对应的state列为nan的值转换为United States of America
cond_usa = pop_abb.state_region == 'USA'
pop_abb['state'][cond_usa] = 'United States of America'
```

```python
# query查询 相当于sql语句中的where
res_2000_pr = pop_abb.query("year=='2000' & state_region=='PR'")
total = res_2000_pr.iloc[0].population
under18 = res_2000_pr.iloc[1].population
```

```python
cond_pop = pop_abb.population.isnull()
cond_2 = pop_abb[cond_pop].age=='under18'

# cond_2是基于pop_abb[cond_pop]
new_under18 = pop_abb[cond_pop][cond_2]

new_under18.population = under18

# 找到对应原对象的行索引
indexs = pop_abb[cond_pop][cond_2].index

pop_abb.loc[indexs] = new_under18
```

```python
# 填补total
cond_3 = pop_abb[cond_pop].ages == 'total'
new_total = pop_abb[cond_pop][cond_3]

new_total.population = total

# 找到对应的原对象的行索引
indexs = pop_abb[cond_pop][cond_3].index
pop_abb.loc[index] = new_total
```

```python
# 合并ares
pop_abb_are = pd.merge(pop_abb, are, how='outer')

pop_abb_ are.isnull().sum()

# 替换列名
cols = pop_abb_are.columns.tolist()
cols[-1] = 'area'
pop_abb_are.columns = cols


# 筛选谁的面积值为nan
cond_are = pop_abb_are.isnull()

pop_abb_are['state'][cond_are]

# 计算 美国总面积 = 各个州面积之和
usa_are = pop_abb_are.query("year=='2012' & ages=='total' & state_region != 'USA'").area.sum()

new = pop_abb_are.query("state_region == 'USA'")
indexs = new.index
new_area = usa_area
pop_abb_are.loc[index] = new
```

```python
# 查找2010年个州 未成年人数和成年人数
u18 = pop_abb_are.query("year=='2010' & ages == 'under18'").population()
total = pop_abb_are.query("year=='2010' & ages == 'total'").population()

```

